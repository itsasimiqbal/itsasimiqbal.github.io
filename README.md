## About Me:
<p>
  I am working as a Postdoctoral Researcher in Computational Neuroscience at
  <a href="https://ethz.ch/en.html"><img src="https://www.simplyscience.ch/assets/images/6/Logo_UZH_ETHZ-34d67296.jpg" width="125" height="20" /> </a>
  . Prior to this, I finished my PhD in Computational Neuroscience on the topic: 'Exploring brain-wide development through deep learning' at Institut für Hirnforschung (HiFo) and Zentrum für Neurowissenschaften Zürich (ZNZ), UZH|ETH Zürich. My PhD thesis was advised by Prof. Theofanis Karayannis along with Prof. Fritjof Helmchen and Prof. Mehmet Fatih Yanik as advisory committe members. The focus of my PhD project was to develop deep learning-based tools to analyse neuro-imaging datasets which includes detection of neurons and generating an automated atlas for developing mouse and human brain sections captured through various imaging modalities. Morover, I worked on explaining the functional and anatomical correlates of neural responses in the mouse somatosensory and visual cortex.</p>

<p> Before starting my PhD, I did Masters in Neural Systems and Computation at Institute of Neuroinformatics (
  <a href="http://www.ini.ethz.ch/"><img src="https://www.ini.uzh.ch/dam/jcr:b79ff425-53c5-4c72-83bd-93e81d3c6e94/neuroman_large.jpg" width="15" height="20" /> </a>
  ), Department of IT and Electrical Engineering (D-ITET), ETH Zürich and worked on enhancing scale-invariance in a convolutional neural network by introducing a neuro-inspired layer that mimics the functionality of complex neurons in the visual cortex. Moreover, I developed a robust framework to detect very fast moving objects in real-time through frame-based running deep neural network with an interface to a spike-based running neuromorphic retina sensor. My Master thesis was advised by Prof. Shih-Chii Liu, Prof. Tobi Delbruck and Prof. Rodney Douglas.</p>

<p> From Summer 2019 to Spring 2020, I worked as an Artificial Intelligence (AI) Resident on a NeuroMoonshot at 
  <a href="https://x.company/"><img src="https://upload.wikimedia.org/wikipedia/commons/e/e3/Google_X_Logo.png" width="62" height="25" /> </a>
  - The Moonshot Factory, Mountain View, California.
</p>

<p> In Summer of 2018, I attended Summer Workshop on the Dynamic Brain (SWDB) at
  <a href="https://alleninstitute.org/what-we-do/brain-science/"><img src="https://www.alleninstitute.org/static/images/logo_BS_header.png" width="90" height="20" /> </a>
  and
  <a href="https://www.washington.edu/"><img src="https://depts.washington.edu/mcklab/images/UW%20logo.jpg" width="90" height="20" /> </a>
  in Seattle, Washington and worked on developing a deep neural network-based decoder to predict neural responses in mouse visual cortex
</p>

<p> In Summer of 2016, I worked as a Research Intern with Brain-inspired Computing group on classification of hand gestures through deep learning and its implementation on TrueNorth neuromorphic chip at 
  <a href="https://www.research.ibm.com/"><img src="https://www.swissre.com/.imaging/default/dam/institute/images-sri/images-sri-events/IBM-Research.jpg/jcr:content.jpg" width="92" height="11" />
  </a>
  - Almaden, San Jose, California.
</p>

<p> From Spring 2015 to Spring 2016, I worked as a Visiting Researcher in DiCarlo's lab, Brain and Cognitive Sciences Department, 
  <a href="http://web.mit.edu/"><img src="https://www.pngitem.com/pimgs/m/359-3591131_massachusetts-institute-of-technology-logo-png-transparent-png.png" width="72" height="20" />
  </a>at Cambridge, Massachusetts. I worked on predicting neural responses in primate visual cortex through performance optimzed deep neural networks.
</p>


## Research Interests:
My research interests broadly categorize into the following:
<p>- Neuro-inspired Artificial Intelligence</p>
<p>- Neuroimaging</p>
<p>- Reinforcement Learning</p>
<p>- Neuromorphic Engineering</p>

<p>In general, I have been working on exploring the functionality of cortical neurons in the developing mouse brain. Some of my recent efforts in this direction has resulted into high-throughput deep learning-based tools to analyse large scale brain imaging datasets. </p>

## Publications:
<p>Rahel Kastli*, Rasmus Vighagen*, Alexander van der Bourg*, Ali Ozgur Argunsah*, <b>Asim Iqbal</b>, Fabian F. Voigt, Daniel Kirschenbaum, Adriano Aguzzi, Fritjof Helmchen, and Theofanis Karayannis. "Developmental divergence of sensory stimulus representation in cortical interneurons." <b><i>bioRxiv</i></b> (2020).<a href="https://www.biorxiv.org/content/10.1101/2020.04.28.065680v1.full.pdf" style="color:green"><b>[paper]</b></a></p>

<p><b>Asim Iqbal</b>, Asfandyar Sheikh, and Theofanis Karayannis. "DeNeRD: high-throughput detection of neurons for brain-wide analysis with deep learning." <b><i>Nature Scientific Reports</i></b> 9, no. 1 (2019): 1-13.<a href="https://rdcu.be/b4DfY" style="color:green"><b>[paper]</b></a></p>

<p><b>Asim Iqbal</b>, Phil Dong, Christopher M. Kim, and Heeun Jang. "Decoding neural responses in mouse visual cortex through a deep neural network." In <b><i>International Joint Conference on Neural Networks (IJCNN)</i></b>, pp. 1-7. IEEE, 2019.<a href="https://arxiv.org/pdf/1911.05479.pdf" style="color:green"><b>[paper]</b></a></p>

<p><b>Asim Iqbal</b>, Romesa Khan, and Theofanis Karayannis. "Developing a brain atlas through deep learning." <b><i>Nature Machine Intelligence</i></b> 1, no. 6 (2019): 277-287.<a href="https://rdcu.be/b4DfW" style="color:green"><b>[paper]</b></a></p>

<p><b>Asim Iqbal</b>, Asfandyar Sheikh, and Theofanis Karayannis. "Exploring brain-wide development of inhibition through deep learning. <b><i>arXiv</i></b> (2018).<a href="https://arxiv.org/pdf/1807.03238.pdf" style="color:green"><b>[paper]</b></a></p>

## News:
<p>Coming soon</p>

## Projects:
#### [SeBRe]: Segmenting Brain Regions with deep learning
<p><a href="https://www.nature.com/natmachintell/volumes/1/issues/6"><img src="/img/SeBRe_Cover_Hero_Image_NMI-1568x1136.jpg" align="left" width="295" height="200" /> </a>
  <a href="https://www.nature.com/natmachintell/volumes/1/issues/6"><img src="/img/6.png" align="right" width="156" height="200" /> </a>
</p>

<p>
  One of the main challenges faced by biologists in general and neuroscientists in partcular is to register mouse/human brain section images to a standard reference atlas. It requires an anatomical expert with a basic training to recognise and precisely annotate brain regions which is a very time consuming and exhausting process. Although, transformation algorithms have tackeled the automdated brain image registration problem to a large extent but they still require fine tuning of parameters for an unseen brain section image. This fine tuning easily takes hours as these algorithms are just trying to minimise a cost function to match the input image to a reference image. Furthermore, these algorithms are prone to errors and cannot simple work if any brain region is missing or distorted.
We introduce a concept of <b>registration through segmentation</b>, we train a deep learning model for instance segmentation to classify and segment all the brain regions in a given image with high accuracy. This approach is independent of data modality and can also serve to help generate an atlas for brain ages on which no atlas is available. Hence, developing a brain atlas through deep learning. Our study is published in Nature Machine Intelligence and made it to the cover of the journal. 
  <a href="https://rdcu.be/b4DfW" style="color:green"><b>[paper]</b></a> 
  <a href="https://github.com/itsasimiqbal/SeBRe" style="color:green"><b>[code]</b></a>
</p>
<p><a href="https://www.nature.com/natmachintell/volumes/1/issues/6"><img src="/img/6.png" align="centre" width="295" height="370" /> </a></p>

## Code:
<p>Coming soon</p>

## Teaching:
<p>Coming soon</p>

## Thoughts:
<p>Coming soon</p>
